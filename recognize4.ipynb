{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee01442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66508698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34edc58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"input/train.csv\")\n",
    "test_data = pd.read_csv(\"input/test.csv\")\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9152e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1) (70000,)\n"
     ]
    }
   ],
   "source": [
    "#loading the MNIST dataset\n",
    "(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n",
    "\n",
    "#join the training and testing set\n",
    "x_train1 = np.concatenate((x_test1, x_train1)) \n",
    "y_train1 = np.concatenate((y_test1, y_train1))\n",
    "\n",
    "#Reshaping the array\n",
    "x_train1 = x_train1.reshape((x_train1.shape[0], 28, 28, 1))\n",
    "print(x_train1.shape, y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51faa3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the label from dataset\n",
    "x = np.array(train_data.drop(['label'], axis = 1))\n",
    "\n",
    "#store the label in y variable\n",
    "y = np.array(train_data['label'])\n",
    "test_data = np.array(test_data) #creating a numpy array\n",
    "\n",
    "#Reshaping the array\n",
    "x = x.reshape((x.shape[0], 28, 28, 1)) \n",
    "test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17334703",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x, x_train1))\n",
    "y = np.concatenate((y, y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a03848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 28, 28, 1) (112000, 10)\n"
     ]
    }
   ],
   "source": [
    "#normalizing the pixel values\n",
    "x = x/255\n",
    "test_data = test_data/255\n",
    "y = to_categorical(y, num_classes = 10)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ca9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100800, 28, 28, 1) (100800, 10) (11200, 28, 28, 1) (11200, 10)\n"
     ]
    }
   ],
   "source": [
    "#Split the array into random train and test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10, shuffle = True)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808fca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train1[0])\n",
    "plt.show()\n",
    "plt.imshow(x_train1[0],cmap=plt.cm.binary)\n",
    "y_train1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d7ce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12, 12, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,978\n",
      "Trainable params: 271,658\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dropout(0.30))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = RMSprop(learning_rate = 0.01, rho = 0.9, epsilon = 1e-08, decay = 0.0)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c657fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range = 10, zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1,)\n",
    "\n",
    "train_batch = datagen.flow(x, y, batch_size = 64)\n",
    "val_batch = datagen.flow(x_test, y_test, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52efee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates.\n",
    "This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate\n",
    "is reduced.'''\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.1, min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8acc2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 101s 57ms/step - loss: 0.3724 - accuracy: 0.9081 - val_loss: 0.2755 - val_accuracy: 0.9476 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 101s 58ms/step - loss: 0.2381 - accuracy: 0.9560 - val_loss: 0.5323 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 101s 58ms/step - loss: 0.2807 - accuracy: 0.9567 - val_loss: 0.1928 - val_accuracy: 0.9708 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 100s 57ms/step - loss: 0.3063 - accuracy: 0.9563 - val_loss: 0.2605 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 105s 60ms/step - loss: 0.3276 - accuracy: 0.9550 - val_loss: 0.2518 - val_accuracy: 0.9666 - lr: 0.0100\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.9513\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1750/1750 [==============================] - 97s 56ms/step - loss: 0.3647 - accuracy: 0.9513 - val_loss: 0.3994 - val_accuracy: 0.9287 - lr: 0.0100\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 96s 55ms/step - loss: 0.1640 - accuracy: 0.9745 - val_loss: 0.0703 - val_accuracy: 0.9886 - lr: 1.0000e-03\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 100s 57ms/step - loss: 0.1393 - accuracy: 0.9804 - val_loss: 0.0526 - val_accuracy: 0.9894 - lr: 1.0000e-03\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 98s 56ms/step - loss: 0.1250 - accuracy: 0.9821 - val_loss: 0.0623 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 99s 57ms/step - loss: 0.1224 - accuracy: 0.9835 - val_loss: 0.0608 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 99s 56ms/step - loss: 0.1135 - accuracy: 0.9842 - val_loss: 0.0488 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 97s 56ms/step - loss: 0.1256 - accuracy: 0.9824 - val_loss: 0.0524 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 97s 56ms/step - loss: 0.1061 - accuracy: 0.9836 - val_loss: 0.0433 - val_accuracy: 0.9913 - lr: 1.0000e-03\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 93s 53ms/step - loss: 0.1046 - accuracy: 0.9836 - val_loss: 0.0479 - val_accuracy: 0.9911 - lr: 1.0000e-03\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 93s 53ms/step - loss: 0.1026 - accuracy: 0.9845 - val_loss: 0.0636 - val_accuracy: 0.9879 - lr: 1.0000e-03\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 93s 53ms/step - loss: 0.1027 - accuracy: 0.9837 - val_loss: 0.0419 - val_accuracy: 0.9920 - lr: 1.0000e-03\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 93s 53ms/step - loss: 0.1033 - accuracy: 0.9836 - val_loss: 0.0487 - val_accuracy: 0.9885 - lr: 1.0000e-03\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 94s 54ms/step - loss: 0.1002 - accuracy: 0.9846 - val_loss: 0.1132 - val_accuracy: 0.9880 - lr: 1.0000e-03\n",
      "Epoch 19/20\n",
      "1749/1750 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 0.9836\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1750/1750 [==============================] - 93s 53ms/step - loss: 0.1030 - accuracy: 0.9836 - val_loss: 0.1815 - val_accuracy: 0.9887 - lr: 1.0000e-03\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 92s 53ms/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 0.0615 - val_accuracy: 0.9935 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "#Training the model for a fixed number of epochs(iterations on a dataset).\n",
    "history = model.fit(train_batch,\n",
    "                              epochs = 20, \n",
    "                              steps_per_epoch = len(train_batch),\n",
    "                              validation_data = val_batch,\n",
    "                              validation_steps = len(val_batch),\n",
    "                              verbose = 1,\n",
    "                             callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43c7055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 11s 100ms/step - loss: 0.5300 - accuracy: 0.9940\n",
      "99.39910769462585\n"
     ]
    }
   ],
   "source": [
    "#Finding the loss value & metrics values for the model in test mode.\n",
    "res = model.evaluate(x, y, batch_size = 1024)\n",
    "print(res[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9384a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\adila\\Documents\\handwritten_digit_recognition\\model4\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:\\\\Users\\\\adila\\\\Documents\\\\handwritten_digit_recognition\\\\model4\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44d226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
